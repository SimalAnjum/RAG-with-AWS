{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3 faiss-cpu datasets sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOQn_NBhqMdX",
        "outputId": "42bb0d86-f77a-41a9-c111-e9a5ff787b52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (1.37.10)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.10 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.37.10)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.11.4)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.10->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.10->boto3) (2.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.10->boto3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AWS Resources Setup"
      ],
      "metadata": {
        "id": "xkOFiHccvSFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import boto3\n",
        "import faiss\n",
        "import json\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# AWS Configuration\n",
        "AWS_REGION = \"us-east-1\"  # Change this to your AWS region\n",
        "S3_BUCKET = \"document-qna-bucket\"\n",
        "AWS_ACCESS_KEY = \"AKIAST6S7QZHY6PJ6BEJ\"\n",
        "AWS_SECRET_KEY = \"GXCEjdNooyC28ABbk9aMpMcSfNlbGSVp+XyV+ymE\"\n",
        "\n",
        "# Initialize AWS Clients\n",
        "s3 = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY,\n",
        "    region_name=AWS_REGION,\n",
        ")\n",
        "\n",
        "textract = boto3.client(\n",
        "    \"textract\",\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY,\n",
        "    region_name=AWS_REGION,\n",
        ")\n",
        "\n",
        "# Load SentenceTransformer model for local testing\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize FAISS index\n",
        "D = 384  # Embedding dimension\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(D))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRczVVtCqYbW",
        "outputId": "6a6b7456-4999-4e4c-c22c-ee0559135bdb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "S3 Test"
      ],
      "metadata": {
        "id": "xw1kdqpavV8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "AWS_REGION = \"us-east-1\"\n",
        "S3_BUCKET = \"document-qna-bucket\"\n",
        "AWS_ACCESS_KEY = \"AKIAST6S7QZHY6PJ6BEJ\"\n",
        "AWS_SECRET_KEY = \"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\"\n",
        "\n",
        "s3 = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY,\n",
        "    region_name=AWS_REGION\n",
        ")\n",
        "\n",
        "# Upload a test file\n",
        "s3.upload_file(\"/content/project_proposal_2.pdf\", S3_BUCKET, \"test.pdf\")\n",
        "print(\"File uploaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k46c6_HujLE",
        "outputId": "a7f7757b-6102-435e-adae-2a7c828429f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Textract Test"
      ],
      "metadata": {
        "id": "aN2coYJTvYck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "textract = boto3.client(\n",
        "    \"textract\",\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY,\n",
        "    region_name=AWS_REGION\n",
        ")\n",
        "\n",
        "def extract_text_from_s3(s3_bucket, file_name):\n",
        "    response = textract.analyze_document(\n",
        "        Document={\"S3Object\": {\"Bucket\": s3_bucket, \"Name\": file_name}},\n",
        "        FeatureTypes=[\"TABLES\", \"FORMS\"]\n",
        "    )\n",
        "\n",
        "    extracted_text = []\n",
        "    for block in response[\"Blocks\"]:\n",
        "        if block[\"BlockType\"] == \"LINE\":\n",
        "            extracted_text.append(block[\"Text\"])\n",
        "\n",
        "    return \"\\n\".join(extracted_text)\n",
        "\n",
        "text = extract_text_from_s3(S3_BUCKET, \"test.pdf\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p-nX0LXvK0r",
        "outputId": "54319e15-0ea0-4053-b2ed-3f8a5b474689"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real-Time Document Question-Answering with LLMs on AWS: Architecture,\n",
            "Performance, and Practical Use Cases\n",
            "Dua e Sameen (ds07138), Muhammad Tahir Ghazi (mg07593), Simal Anjum (sa07716)\n",
            "Description:\n",
            "A scalable, real-time Q&A system leveraging AWS capabilities, reducing information\n",
            "retrieval time for large document repositories.\n",
            "Abstract:\n",
            "This project proposes a real-time document question-answering system leveraging AWS\n",
            "services to efficiently retrieve relevant information from large document repositories. By\n",
            "integrating Amazon S3 for document storage, Amazon Textract for text extraction, and\n",
            "Amazon SageMaker for embedding and LLM-based responses, the system ensures high\n",
            "scalability and low latency. A vector database, such as FAISS or Pinecone, facilitates efficient\n",
            "retrieval, while AWS Lambda and API Gateway enable seamless user interactions. The solution\n",
            "is particularly beneficial for industries requiring rapid compliance checks, legal document\n",
            "analysis, and customer support automation. To stay within AWS Free Tier limits, alternative\n",
            "workarounds may be explored, such as local text extraction or self-hosted embedding models,\n",
            "if necessary. Through optimized performance metrics, including latency and retrieval accuracy,\n",
            "this system aims to enhance productivity by delivering precise answers instantly.\n",
            "Proposed Schedule:\n",
            "Week\n",
            "Milestones\n",
            "Tasks\n",
            "1\n",
            "Project Plan\n",
            "Requirement Gathering\n",
            "AWS account setup\n",
            "Research into Existing Solutions\n",
            "2\n",
            "Data Storage and Text Extraction\n",
            "Setup S3\n",
            "Implement Amazon Textract\n",
            "3\n",
            "Embeddings and Vector DB Setup\n",
            "Use SageMaker for processing\n",
            "text into embeddings\n",
            "FAISS for storage of embeddings\n",
            "Retrieve relevant text\n",
            "4-5\n",
            "LLM Integration & Query Processing\n",
            "Setting up LLM-based Question\n",
            "Answering\n",
            "Handling user queries\n",
            "Response generation using LLM\n",
            "6-7\n",
            "Optimization & FrontEnd\n",
            "Work on improving accuracy\n",
            "Try to optimize retrieval latency\n",
            "Develop a simple user friendly\n",
            "frontend.\n",
            "8-9\n",
            "Testing & Final Report\n",
            "Datasets we are exploring: SQuAD v2.0 and CUAD\n",
            "*Where necessary we may opt for alternatives to AWS services to stay within the limits of the free tier.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Loading"
      ],
      "metadata": {
        "id": "DDxlGtCTxWHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJFKnuUvxC5F",
        "outputId": "8461c44c-642d-483e-ca77-f15f7dfde274"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAISS Index in S3"
      ],
      "metadata": {
        "id": "3sV6PdI43I6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "# Save FAISS index to S3\n",
        "def save_faiss_index():\n",
        "    index_path = \"/tmp/faiss.index\"\n",
        "    faiss.write_index(index, index_path)\n",
        "    s3.upload_file(index_path, S3_BUCKET, \"faiss.index\")\n",
        "    print(\"FAISS index saved to S3.\")\n",
        "\n",
        "# Load FAISS index from S3\n",
        "def load_faiss_index():\n",
        "    index_path = \"/tmp/faiss.index\"\n",
        "    s3.download_file(S3_BUCKET, \"faiss.index\", index_path)\n",
        "    global index\n",
        "    index = faiss.read_index(index_path)\n",
        "    print(\"FAISS index loaded from S3.\")\n"
      ],
      "metadata": {
        "id": "SYZxfLKHxTBO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploying API"
      ],
      "metadata": {
        "id": "Dw9SG-i23Vua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import boto3\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "s3 = boto3.client(\"s3\")\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "FAISS_INDEX_BUCKET = \"document-qna-bucket\"\n",
        "\n",
        "# Load FAISS index from S3\n",
        "def load_faiss_index():\n",
        "    index_path = \"/tmp/faiss.index\"\n",
        "    s3.download_file(FAISS_INDEX_BUCKET, \"faiss.index\", index_path)\n",
        "    global index\n",
        "    index = faiss.read_index(index_path)\n",
        "\n",
        "def query_faiss(question):\n",
        "    query_embedding = embedding_model.encode(question, convert_to_numpy=True)\n",
        "    query_embedding = np.expand_dims(query_embedding, axis=0).astype(np.float32)\n",
        "\n",
        "    _, indices = index.search(query_embedding, k=1)\n",
        "    best_match_id = indices[0][0]\n",
        "\n",
        "    return f\"Best matching document ID: {best_match_id}\"\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    question = event[\"queryStringParameters\"][\"question\"]\n",
        "    load_faiss_index()\n",
        "    answer = query_faiss(question)\n",
        "    return {\"statusCode\": 200, \"body\": json.dumps({\"answer\": answer})}\n"
      ],
      "metadata": {
        "id": "854sySJXxea5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://5dkbjaf0t5.execute-api.us-east-1.amazonaws.com/deployment\"\n",
        "params = {\"question\": \"What is the liability clause?\"}\n",
        "\n",
        "response = requests.get(API_URL, params=params)\n",
        "\n",
        "print(response.json())  # Should return the processed answer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__7VQe32uRe",
        "outputId": "63c6ec48-7c8e-4ac8-ac18-80e15cad2932"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'statusCode': 200, 'body': '\"Hello from Lambda!\"'}\n"
          ]
        }
      ]
    }
  ]
}